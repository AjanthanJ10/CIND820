{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIND 820: Big Data Analytics Project - Initial Results and the Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, average_precision_score, confusion_matrix, roc_curve, precision_recall_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset, Creating Features and Target, and Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-Square and ANOVA F-test Scores:\n",
      "                 Feature     Chi2 Score  ANOVA F Score\n",
      "21               BMI_Age  922213.400451   11905.944685\n",
      "15              PhysHlth  141598.783225    4078.699854\n",
      "14              MentHlth   24607.463010     717.117372\n",
      "3                    BMI   19775.252090    6768.361067\n",
      "22       HighBP_HighChol   14392.694424   10453.965178\n",
      "0                 HighBP   10731.721009   10149.140418\n",
      "16              DiffWalk   10627.556856    6727.221134\n",
      "13               GenHlth   10595.234173   12832.660123\n",
      "18                   Age   10225.159975    4560.441068\n",
      "6   HeartDiseaseorAttack    7468.339377    4260.879233\n",
      "1               HighChol    6483.776499    5890.843228\n",
      "20                Income    5380.434934    3913.752954\n",
      "23      PhysActivity_BMI    3981.998963     244.921534\n",
      "5                 Stroke    2798.417025    1475.321639\n",
      "7           PhysActivity     922.529401    1923.358158\n",
      "19             Education     849.169260    2245.725730\n",
      "10     HvyAlcoholConsump     802.538572     426.586896\n",
      "4                 Smoker     562.684715     507.270568\n",
      "12           NoDocbcCost     362.740875     198.348259\n",
      "9                Veggies     168.560797     448.495944\n",
      "8                 Fruits     166.174822     227.578441\n",
      "17                   Sex     140.390490     125.547952\n",
      "2              CholCheck      43.816645     589.595733\n",
      "11         AnyHealthcare       3.381194      34.547987\n",
      "\n",
      "6 Lowest-Scoring Features to be Dropped:\n",
      "['AnyHealthcare', 'CholCheck', 'Sex', 'Fruits', 'Veggies', 'NoDocbcCost']\n",
      "\n",
      "Final 15 Features Used:\n",
      "['HighBP', 'HighChol', 'BMI', 'Smoker', 'Stroke', 'HeartDiseaseorAttack', 'PhysActivity', 'HvyAlcoholConsump', 'GenHlth', 'MentHlth', 'PhysHlth', 'DiffWalk', 'Age', 'Education', 'Income', 'BMI_Age', 'HighBP_HighChol', 'PhysActivity_BMI']\n"
     ]
    }
   ],
   "source": [
    "# Load your dataset\n",
    "file_path = \"/Users/ajanthanjoseph/Documents/GitHub/CIND820/diabetes_012_health_indicators_BRFSS2015.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Create interaction features\n",
    "df[\"BMI_Age\"] = df[\"BMI\"] * df[\"Age\"]\n",
    "df[\"HighBP_HighChol\"] = df[\"HighBP\"] * df[\"HighChol\"]\n",
    "df[\"PhysActivity_BMI\"] = df[\"PhysActivity\"] * df[\"BMI\"]\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=[\"Diabetes_012\"])\n",
    "y = df[\"Diabetes_012\"]\n",
    "\n",
    "# Apply Chi-Squared test for feature selection\n",
    "chi2_selector = SelectKBest(score_func=chi2, k='all')\n",
    "chi2_selector.fit(X, y)\n",
    "chi2_scores = chi2_selector.scores_\n",
    "\n",
    "# Apply ANOVA F-test for feature selection\n",
    "anova_selector = SelectKBest(score_func=f_classif, k='all')\n",
    "anova_selector.fit(X, y)\n",
    "anova_scores = anova_selector.scores_\n",
    "\n",
    "# Create a DataFrame with the feature selection results\n",
    "feature_selection_results = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Chi2 Score': chi2_scores,\n",
    "    'ANOVA F Score': anova_scores\n",
    "}).sort_values(by=['Chi2 Score', 'ANOVA F Score'], ascending=False)\n",
    "\n",
    "# Display Chi-Square and ANOVA scores\n",
    "print(\"Chi-Square and ANOVA F-test Scores:\")\n",
    "print(feature_selection_results)\n",
    "\n",
    "# Identify the 6 lowest scoring features based on the combined scores\n",
    "lowest_features = feature_selection_results.nsmallest(6, ['Chi2 Score', 'ANOVA F Score'])['Feature'].tolist()\n",
    "\n",
    "# Display the 6 lowest-scoring features to be dropped\n",
    "print(\"\\n6 Lowest-Scoring Features to be Dropped:\")\n",
    "print(lowest_features)\n",
    "\n",
    "# Drop these features from the dataset\n",
    "X_reduced = X.drop(columns=lowest_features)\n",
    "\n",
    "# Display the final 15 features used\n",
    "print(\"\\nFinal 15 Features Used:\")\n",
    "print(X_reduced.columns.tolist())\n",
    "\n",
    "# Standardize numerical columns\n",
    "numerical_features = [\"BMI\", \"Age\", \"BMI_Age\", \"PhysActivity_BMI\"]\n",
    "scaler = StandardScaler()\n",
    "X_reduced[numerical_features] = scaler.fit_transform(X_reduced[numerical_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting unbalanced dataset into Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and Testing Dataset Shapes (Unbalanced):\n",
      "X_train_unbalanced: (177576, 18), y_train_unbalanced: (177576,)\n",
      "X_test_unbalanced: (76104, 18), y_test_unbalanced: (76104,)\n"
     ]
    }
   ],
   "source": [
    "# Split the original (unbalanced) dataset into training and testing sets\n",
    "X_train_unbalanced, X_test_unbalanced, y_train_unbalanced, y_test_unbalanced = train_test_split(\n",
    "    X_reduced, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Display the shapes of the resulting datasets\n",
    "print(\"Training and Testing Dataset Shapes (Unbalanced):\")\n",
    "print(f\"X_train_unbalanced: {X_train_unbalanced.shape}, y_train_unbalanced: {y_train_unbalanced.shape}\")\n",
    "print(f\"X_test_unbalanced: {X_test_unbalanced.shape}, y_test_unbalanced: {y_test_unbalanced.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unbalanced Data Machine Learning Models + Evaluation of Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ajanthanjoseph/Documents/GitHub/CIND820/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Evaluation (Unbalanced Data):\n",
      "Accuracy: 0.8470908230842006\n",
      "Precision: 0.8005741870177647\n",
      "Recall: 0.8470908230842006\n",
      "ROC AUC: 0.7788126815121236\n",
      "PR AUC: 0.8637734630283154\n",
      "Confusion Matrix:\n",
      "[[62587     0  1524]\n",
      " [ 1252     0   137]\n",
      " [ 8724     0  1880]]\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "lr_unbalanced = LogisticRegression(max_iter=1000)\n",
    "lr_unbalanced.fit(X_train_unbalanced, y_train_unbalanced)\n",
    "y_pred_unbalanced = lr_unbalanced.predict(X_test_unbalanced)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test_unbalanced, y_pred_unbalanced)\n",
    "precision = precision_score(y_test_unbalanced, y_pred_unbalanced, average='weighted')\n",
    "recall = recall_score(y_test_unbalanced, y_pred_unbalanced, average='weighted')\n",
    "roc_auc = roc_auc_score(y_test_unbalanced, lr_unbalanced.predict_proba(X_test_unbalanced), multi_class='ovr')\n",
    "pr_auc = average_precision_score(y_test_unbalanced, lr_unbalanced.predict_proba(X_test_unbalanced), average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test_unbalanced, y_pred_unbalanced)\n",
    "\n",
    "print(\"Logistic Regression Evaluation (Unbalanced Data):\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"ROC AUC: {roc_auc}\")\n",
    "print(f\"PR AUC: {pr_auc}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Evaluation (Unbalanced Data):\n",
      "Accuracy: 0.8354357195416798\n",
      "Precision: 0.7919413847306005\n",
      "Recall: 0.8354357195416798\n",
      "ROC AUC: 0.7242430981275967\n",
      "PR AUC: 0.84344441378793\n",
      "Confusion Matrix:\n",
      "[[61267   136  2708]\n",
      " [ 1192     4   193]\n",
      " [ 8266    29  2309]]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf_unbalanced = RandomForestClassifier(random_state=42)\n",
    "rf_unbalanced.fit(X_train_unbalanced, y_train_unbalanced)\n",
    "y_pred_unbalanced = rf_unbalanced.predict(X_test_unbalanced)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test_unbalanced, y_pred_unbalanced)\n",
    "precision = precision_score(y_test_unbalanced, y_pred_unbalanced, average='weighted')\n",
    "recall = recall_score(y_test_unbalanced, y_pred_unbalanced, average='weighted')\n",
    "roc_auc = roc_auc_score(y_test_unbalanced, rf_unbalanced.predict_proba(X_test_unbalanced), multi_class='ovr')\n",
    "pr_auc = average_precision_score(y_test_unbalanced, rf_unbalanced.predict_proba(X_test_unbalanced), average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test_unbalanced, y_pred_unbalanced)\n",
    "\n",
    "print(\"Random Forest Evaluation (Unbalanced Data):\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"ROC AUC: {roc_auc}\")\n",
    "print(f\"PR AUC: {pr_auc}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Evaluation (Unbalanced Data):\n",
      "Accuracy: 0.7787895511405445\n",
      "Precision: 0.7819235410992261\n",
      "Recall: 0.7787895511405445\n",
      "ROC AUC: 0.5700011456996527\n",
      "PR AUC: 0.7621174387535227\n",
      "Confusion Matrix:\n",
      "[[55890  1207  7014]\n",
      " [ 1005    47   337]\n",
      " [ 6908   364  3332]]\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "dt_unbalanced = DecisionTreeClassifier(random_state=42)\n",
    "dt_unbalanced.fit(X_train_unbalanced, y_train_unbalanced)\n",
    "y_pred_unbalanced = dt_unbalanced.predict(X_test_unbalanced)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test_unbalanced, y_pred_unbalanced)\n",
    "precision = precision_score(y_test_unbalanced, y_pred_unbalanced, average='weighted')\n",
    "recall = recall_score(y_test_unbalanced, y_pred_unbalanced, average='weighted')\n",
    "roc_auc = roc_auc_score(y_test_unbalanced, dt_unbalanced.predict_proba(X_test_unbalanced), multi_class='ovr')\n",
    "pr_auc = average_precision_score(y_test_unbalanced, dt_unbalanced.predict_proba(X_test_unbalanced), average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test_unbalanced, y_pred_unbalanced)\n",
    "\n",
    "print(\"Decision Tree Evaluation (Unbalanced Data):\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"ROC AUC: {roc_auc}\")\n",
    "print(f\"PR AUC: {pr_auc}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost Evaluation (Unbalanced Data):\n",
      "Accuracy: 0.8485756333438452\n",
      "Precision: 0.8032305623999324\n",
      "Recall: 0.8485756333438452\n",
      "ROC AUC: 0.7759753797830875\n",
      "PR AUC: 0.8675871220801562\n",
      "Confusion Matrix:\n",
      "[[62688     0  1423]\n",
      " [ 1249     0   140]\n",
      " [ 8710     2  1892]]\n"
     ]
    }
   ],
   "source": [
    "# CatBoost\n",
    "cb_unbalanced = CatBoostClassifier(random_state=42, verbose=0)\n",
    "cb_unbalanced.fit(X_train_unbalanced, y_train_unbalanced)\n",
    "y_pred_unbalanced = cb_unbalanced.predict(X_test_unbalanced)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test_unbalanced, y_pred_unbalanced)\n",
    "precision = precision_score(y_test_unbalanced, y_pred_unbalanced, average='weighted')\n",
    "recall = recall_score(y_test_unbalanced, y_pred_unbalanced, average='weighted')\n",
    "roc_auc = roc_auc_score(y_test_unbalanced, cb_unbalanced.predict_proba(X_test_unbalanced), multi_class='ovr')\n",
    "pr_auc = average_precision_score(y_test_unbalanced, cb_unbalanced.predict_proba(X_test_unbalanced), average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test_unbalanced, y_pred_unbalanced)\n",
    "\n",
    "print(\"CatBoost Evaluation (Unbalanced Data):\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"ROC AUC: {roc_auc}\")\n",
    "print(f\"PR AUC: {pr_auc}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Evaluation (Unbalanced Data):\n",
      "Accuracy: 0.8497845054136445\n",
      "Precision: 0.805954937607854\n",
      "Recall: 0.8497845054136445\n",
      "ROC AUC: 0.7858889878472901\n",
      "PR AUC: 0.8688348849470646\n",
      "Confusion Matrix:\n",
      "[[62629     0  1482]\n",
      " [ 1244     0   145]\n",
      " [ 8560     1  2043]]\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting\n",
    "gb_unbalanced = GradientBoostingClassifier(random_state=42)\n",
    "gb_unbalanced.fit(X_train_unbalanced, y_train_unbalanced)\n",
    "y_pred_unbalanced = gb_unbalanced.predict(X_test_unbalanced)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test_unbalanced, y_pred_unbalanced)\n",
    "precision = precision_score(y_test_unbalanced, y_pred_unbalanced, average='weighted')\n",
    "recall = recall_score(y_test_unbalanced, y_pred_unbalanced, average='weighted')\n",
    "roc_auc = roc_auc_score(y_test_unbalanced, gb_unbalanced.predict_proba(X_test_unbalanced), multi_class='ovr')\n",
    "pr_auc = average_precision_score(y_test_unbalanced, gb_unbalanced.predict_proba(X_test_unbalanced), average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test_unbalanced, y_pred_unbalanced)\n",
    "\n",
    "print(\"Gradient Boosting Evaluation (Unbalanced Data):\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"ROC AUC: {roc_auc}\")\n",
    "print(f\"PR AUC: {pr_auc}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Evaluation (Unbalanced Data):\n",
      "Accuracy: 0.8481025964469673\n",
      "Precision: 0.8024858420065205\n",
      "Recall: 0.8481025964469673\n",
      "ROC AUC: 0.7750223569889069\n",
      "PR AUC: 0.8667490981502702\n",
      "Confusion Matrix:\n",
      "[[62637     2  1472]\n",
      " [ 1249     0   140]\n",
      " [ 8697     0  1907]]\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "xgb_unbalanced = XGBClassifier(random_state=42)\n",
    "xgb_unbalanced.fit(X_train_unbalanced, y_train_unbalanced)\n",
    "y_pred_unbalanced = xgb_unbalanced.predict(X_test_unbalanced)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test_unbalanced, y_pred_unbalanced)\n",
    "precision = precision_score(y_test_unbalanced, y_pred_unbalanced, average='weighted')\n",
    "recall = recall_score(y_test_unbalanced, y_pred_unbalanced, average='weighted')\n",
    "roc_auc = roc_auc_score(y_test_unbalanced, xgb_unbalanced.predict_proba(X_test_unbalanced), multi_class='ovr')\n",
    "pr_auc = average_precision_score(y_test_unbalanced, xgb_unbalanced.predict_proba(X_test_unbalanced), average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test_unbalanced, y_pred_unbalanced)\n",
    "\n",
    "print(\"XGBoost Evaluation (Unbalanced Data):\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"ROC AUC: {roc_auc}\")\n",
    "print(f\"PR AUC: {pr_auc}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying SMOTE to balance the target classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Models and Evaluation using the balanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diabetes_012\n",
      "0.0    213703\n",
      "2.0    213703\n",
      "1.0    213703\n",
      "Name: count, dtype: int64\n",
      "Training and Testing Dataset Shapes:\n",
      "X_train: (448776, 18), y_train: (448776,)\n",
      "X_test: (192333, 18), y_test: (192333,)\n"
     ]
    }
   ],
   "source": [
    "# Apply SMOTE to balance the target classes\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_reduced, y)\n",
    "\n",
    "# Check the distribution of the target variable after SMOTE\n",
    "print(y_resampled.value_counts())\n",
    "\n",
    "# Split the data into training and testing sets with a 70-30 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled, y_resampled, test_size=0.3, random_state=42, stratify=y_resampled\n",
    ")\n",
    "\n",
    "# Display the shapes of the resulting datasets\n",
    "print(\"Training and Testing Dataset Shapes:\")\n",
    "print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Evaluation:\n",
      "Accuracy: 0.5308189442269398\n",
      "Precision: 0.5217847413620351\n",
      "Recall: 0.5308189442269398\n",
      "ROC AUC: 0.7199222321201696\n",
      "PR AUC: 0.5587721390821514\n",
      "Confusion Matrix:\n",
      "[[42541 11314 10256]\n",
      " [17537 21368 25206]\n",
      " [10423 15503 38185]]\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "roc_auc = roc_auc_score(y_test, lr.predict_proba(X_test), multi_class='ovr')\n",
    "pr_auc = average_precision_score(y_test, lr.predict_proba(X_test), average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Logistic Regression Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"ROC AUC: {roc_auc}\")\n",
    "print(f\"PR AUC: {pr_auc}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Evaluation:\n",
      "Accuracy: 0.9145076507931557\n",
      "Precision: 0.9146563682283299\n",
      "Recall: 0.9145076507931557\n",
      "ROC AUC: 0.9791985358879257\n",
      "PR AUC: 0.9605713326310968\n",
      "Confusion Matrix:\n",
      "[[58995   240  4876]\n",
      " [ 1142 61750  1219]\n",
      " [ 6598  2368 55145]]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "roc_auc = roc_auc_score(y_test, rf.predict_proba(X_test), multi_class='ovr')\n",
    "pr_auc = average_precision_score(y_test, rf.predict_proba(X_test), average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Random Forest Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"ROC AUC: {roc_auc}\")\n",
    "print(f\"PR AUC: {pr_auc}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Evaluation:\n",
      "Accuracy: 0.8501661181388529\n",
      "Precision: 0.849375632513043\n",
      "Recall: 0.8501661181388529\n",
      "ROC AUC: 0.8898436677623539\n",
      "PR AUC: 0.7787489927215748\n",
      "Confusion Matrix:\n",
      "[[54830  1474  7807]\n",
      " [ 1281 58550  4280]\n",
      " [ 8158  5818 50135]]\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "roc_auc = roc_auc_score(y_test, dt.predict_proba(X_test), multi_class='ovr')\n",
    "pr_auc = average_precision_score(y_test, dt.predict_proba(X_test), average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Decision Tree Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"ROC AUC: {roc_auc}\")\n",
    "print(f\"PR AUC: {pr_auc}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost Evaluation:\n",
      "Accuracy: 0.8329563829400051\n",
      "Precision: 0.8307461699270817\n",
      "Recall: 0.8329563829400051\n",
      "ROC AUC: 0.9449059727991486\n",
      "PR AUC: 0.9038757312961042\n",
      "Confusion Matrix:\n",
      "[[61705     1  2405]\n",
      " [ 1552 54417  8142]\n",
      " [ 8825 11203 44083]]\n"
     ]
    }
   ],
   "source": [
    "# CatBoost\n",
    "cb = CatBoostClassifier(random_state=42, verbose=0)\n",
    "cb.fit(X_train, y_train)\n",
    "y_pred = cb.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "roc_auc = roc_auc_score(y_test, cb.predict_proba(X_test), multi_class='ovr')\n",
    "pr_auc = average_precision_score(y_test, cb.predict_proba(X_test), average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"CatBoost Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"ROC AUC: {roc_auc}\")\n",
    "print(f\"PR AUC: {pr_auc}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Evaluation:\n",
      "Accuracy: 0.7169180535841483\n",
      "Precision: 0.7146309475644166\n",
      "Recall: 0.7169180535841483\n",
      "ROC AUC: 0.8769130632125709\n",
      "PR AUC: 0.773102404677562\n",
      "Confusion Matrix:\n",
      "[[54754    96  9261]\n",
      " [ 4326 44667 15118]\n",
      " [ 8264 17381 38466]]\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "gb.fit(X_train, y_train)\n",
    "y_pred = gb.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "roc_auc = roc_auc_score(y_test, gb.predict_proba(X_test), multi_class='ovr')\n",
    "pr_auc = average_precision_score(y_test, gb.predict_proba(X_test), average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Gradient Boosting Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"ROC AUC: {roc_auc}\")\n",
    "print(f\"PR AUC: {pr_auc}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Evaluation:\n",
      "Accuracy: 0.8218350465078795\n",
      "Precision: 0.818991530395379\n",
      "Recall: 0.8218350465078795\n",
      "ROC AUC: 0.9395522710431691\n",
      "PR AUC: 0.8936095904496358\n",
      "Confusion Matrix:\n",
      "[[61367     0  2744]\n",
      " [ 1820 53263  9028]\n",
      " [ 8850 11825 43436]]\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "xgb = XGBClassifier(random_state=42)\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred = xgb.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "roc_auc = roc_auc_score(y_test, xgb.predict_proba(X_test), multi_class='ovr')\n",
    "pr_auc = average_precision_score(y_test, xgb.predict_proba(X_test), average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"XGBoost Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"ROC AUC: {roc_auc}\")\n",
    "print(f\"PR AUC: {pr_auc}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Including HyperParameter Boosting using RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Logistic Regression and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Logistic Regression: {'solver': 'liblinear', 'penalty': 'l2', 'C': 0.01}\n",
      "Logistic Regression with RandomizedSearchCV Evaluation:\n",
      "Accuracy: 0.5265815018743534\n",
      "Precision: 0.5145368328994473\n",
      "Recall: 0.5265815018743534\n",
      "ROC AUC: 0.7155030946008178\n",
      "PR AUC: 0.55349657492202\n",
      "Confusion Matrix:\n",
      "[[43600  9634 10877]\n",
      " [19011 18124 26976]\n",
      " [11583 12973 39555]]\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression with RandomizedSearchCV\n",
    "param_dist_lr = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear']\n",
    "}\n",
    "\n",
    "lr_random = RandomizedSearchCV(\n",
    "    LogisticRegression(max_iter=1000),\n",
    "    param_distributions=param_dist_lr,\n",
    "    n_iter=10,  \n",
    "    cv=3,       \n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,  \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "lr_random.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and evaluation\n",
    "print(\"Best Parameters for Logistic Regression:\", lr_random.best_params_)\n",
    "y_pred = lr_random.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "roc_auc = roc_auc_score(y_test, lr_random.predict_proba(X_test), multi_class='ovr')\n",
    "pr_auc = average_precision_score(y_test, lr_random.predict_proba(X_test), average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Logistic Regression with RandomizedSearchCV Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"ROC AUC: {roc_auc}\")\n",
    "print(f\"PR AUC: {pr_auc}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Random Forest: {'n_estimators': 200, 'min_samples_split': 5, 'max_depth': 30}\n",
      "Random Forest with RandomizedSearchCV Evaluation:\n",
      "Accuracy: 0.9145336473720058\n",
      "Precision: 0.9146205070922732\n",
      "Recall: 0.9145336473720058\n",
      "ROC AUC: 0.9805480842860151\n",
      "PR AUC: 0.9652321666079307\n",
      "Confusion Matrix:\n",
      "[[59024   139  4948]\n",
      " [ 1127 61594  1390]\n",
      " [ 6354  2480 55277]]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest with RandomizedSearchCV\n",
    "param_dist_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "rf_random = RandomizedSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    param_distributions=param_dist_rf,\n",
    "    n_iter=10,  \n",
    "    cv=3,       \n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,  \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and evaluation\n",
    "print(\"Best Parameters for Random Forest:\", rf_random.best_params_)\n",
    "y_pred = rf_random.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "roc_auc = roc_auc_score(y_test, rf_random.predict_proba(X_test), multi_class='ovr')\n",
    "pr_auc = average_precision_score(y_test, rf_random.predict_proba(X_test), average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Random Forest with RandomizedSearchCV Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"ROC AUC: {roc_auc}\")\n",
    "print(f\"PR AUC: {pr_auc}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Decision Tree: {'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': 30}\n",
      "Decision Tree with RandomizedSearchCV Evaluation:\n",
      "Accuracy: 0.8473896835176491\n",
      "Precision: 0.8463380415331306\n",
      "Recall: 0.8473896835176491\n",
      "ROC AUC: 0.9118613155441437\n",
      "PR AUC: 0.8227700865167803\n",
      "Confusion Matrix:\n",
      "[[56961   868  6282]\n",
      " [ 1609 58572  3930]\n",
      " [ 9386  7277 47448]]\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree with RandomizedSearchCV\n",
    "param_dist_dt = {\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "dt_random = RandomizedSearchCV(\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    param_distributions=param_dist_dt,\n",
    "    n_iter=10,  \n",
    "    cv=3,       \n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,  \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "dt_random.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and evaluation\n",
    "print(\"Best Parameters for Decision Tree:\", dt_random.best_params_)\n",
    "y_pred = dt_random.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "roc_auc = roc_auc_score(y_test, dt_random.predict_proba(X_test), multi_class='ovr')\n",
    "pr_auc = average_precision_score(y_test, dt_random.predict_proba(X_test), average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Decision Tree with RandomizedSearchCV Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"ROC AUC: {roc_auc}\")\n",
    "print(f\"PR AUC: {pr_auc}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for CatBoost: {'learning_rate': 0.2, 'iterations': 300, 'depth': 6}\n",
      "CatBoost with RandomizedSearchCV Evaluation:\n",
      "Accuracy: 0.8072353678255941\n",
      "Precision: 0.8033370692636146\n",
      "Recall: 0.8072353678255941\n",
      "ROC AUC: 0.9311714309519452\n",
      "PR AUC: 0.876704444791425\n",
      "Confusion Matrix:\n",
      "[[61301     0  2810]\n",
      " [ 1775 51985 10351]\n",
      " [ 8939 13200 41972]]\n"
     ]
    }
   ],
   "source": [
    "# CatBoost with RandomizedSearchCV\n",
    "param_dist_cb = {\n",
    "    'iterations': [100, 200, 300],\n",
    "    'depth': [4, 6, 8],\n",
    "    'learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "cb_random = RandomizedSearchCV(\n",
    "    CatBoostClassifier(random_state=42, verbose=0),\n",
    "    param_distributions=param_dist_cb,\n",
    "    n_iter=10,  \n",
    "    cv=3,       \n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,  \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "cb_random.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and evaluation\n",
    "print(\"Best Parameters for CatBoost:\", cb_random.best_params_)\n",
    "y_pred = cb_random.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "roc_auc = roc_auc_score(y_test, cb_random.predict_proba(X_test), multi_class='ovr')\n",
    "pr_auc = average_precision_score(y_test, cb_random.predict_proba(X_test), average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"CatBoost with RandomizedSearchCV Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"ROC AUC: {roc_auc}\")\n",
    "print(f\"PR AUC: {pr_auc}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Gradient Boosting: {'n_estimators': 200, 'max_depth': 4, 'learning_rate': 0.2}\n",
      "Gradient Boosting with RandomizedSearchCV Evaluation:\n",
      "Accuracy: 0.8034086714188413\n",
      "Precision: 0.7989758449276145\n",
      "Recall: 0.8034086714188413\n",
      "ROC AUC: 0.928072320967925\n",
      "PR AUC: 0.8699826224074192\n",
      "Confusion Matrix:\n",
      "[[61681     0  2430]\n",
      " [ 1599 51366 11146]\n",
      " [ 8834 13802 41475]]\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting with RandomizedSearchCV\n",
    "param_dist_gb = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.1, 0.2],\n",
    "    'max_depth': [3, 4]\n",
    "}\n",
    "\n",
    "gb_random = RandomizedSearchCV(\n",
    "    GradientBoostingClassifier(random_state=42),\n",
    "    param_distributions=param_dist_gb,\n",
    "    n_iter=5,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit on the smaller dataset\n",
    "gb_random.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and evaluation\n",
    "print(\"Best Parameters for Gradient Boosting:\", gb_random.best_params_)\n",
    "y_pred = gb_random.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "roc_auc = roc_auc_score(y_test, gb_random.predict_proba(X_test), multi_class='ovr')\n",
    "pr_auc = average_precision_score(y_test, gb_random.predict_proba(X_test), average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Gradient Boosting with RandomizedSearchCV Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"ROC AUC: {roc_auc}\")\n",
    "print(f\"PR AUC: {pr_auc}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for XGBoost: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.1}\n",
      "XGBoost with RandomizedSearchCV Evaluation:\n",
      "Accuracy: 0.7985161152792293\n",
      "Precision: 0.7942678467390154\n",
      "Recall: 0.7985161152792293\n",
      "ROC AUC: 0.9262938062909094\n",
      "PR AUC: 0.8671469144690347\n",
      "Confusion Matrix:\n",
      "[[60880     0  3231]\n",
      " [ 2028 51033 11050]\n",
      " [ 8797 13646 41668]]\n"
     ]
    }
   ],
   "source": [
    "# XGBoost with RandomizedSearchCV\n",
    "param_dist_xgb = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "xgb_random = RandomizedSearchCV(\n",
    "    XGBClassifier(random_state=42),\n",
    "    param_distributions=param_dist_xgb,\n",
    "    n_iter=10,  \n",
    "    cv=3,       \n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,  \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_random.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and evaluation\n",
    "print(\"Best Parameters for XGBoost:\", xgb_random.best_params_)\n",
    "y_pred = xgb_random.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "roc_auc = roc_auc_score(y_test, xgb_random.predict_proba(X_test), multi_class='ovr')\n",
    "pr_auc = average_precision_score(y_test, xgb_random.predict_proba(X_test), average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"XGBoost with RandomizedSearchCV Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"ROC AUC: {roc_auc}\")\n",
    "print(f\"PR AUC: {pr_auc}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
